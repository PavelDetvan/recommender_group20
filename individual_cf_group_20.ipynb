{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 Collaborative filtering\n",
    "## 1.1 Introduction with small fictional database\n",
    "\n",
    "The first thing we want to explore are the possibilities to perform collaborative filtering using singular value decomposition (SVD). We want to do this using the lenskit python-module. Before we apply this module to the wine dataset, we first want to get a better feeling on how this module works. To do so, we first use a small fictional database. The small database is loaded into memory as a pandas dataframe in the cell below.\n",
    "\n",
    "**Important**: Lenskit works only if the version of the python interpreter is >= 3.8 and < 3.12 "
   ],
   "id": "85b2a1b2adc2b4d3"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.756905Z",
     "start_time": "2024-09-24T18:16:17.737326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "fictional_ratings_df = pd.DataFrame({\n",
    "    'user': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7],\n",
    "    'item': [1, 2, 3, 1, 2, 4, 2, 3, 5, 1, 4, 5, 2, 3, 6, 1, 5, 6, 3, 5, 6],\n",
    "    'rating': [5, 3, 4, 4, 5, 2, 3, 4, 5, 3, 2, 4, 5, 4, 3, 4, 5, 3, 4, 5, 4]\n",
    "})"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we want to apply SVD to this database, this dataframa has to be compressed to a sparse row matrix, or CSR-matrix for short. The SVD-models do this automatically, but for the sake of completeness, the CSR-matrix is shown below. Missing values are filled with zeros.",
   "id": "676130af61442cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.800442Z",
     "start_time": "2024-09-24T18:16:17.781419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fictional_ratings_matrix = fictional_ratings_df.pivot(index='user', columns='item', values='rating').fillna(0)\n",
    "\n",
    "print(fictional_ratings_matrix)\n"
   ],
   "id": "d0d8e5d1def4fa7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item    1    2    3    4    5    6\n",
      "user                              \n",
      "1     5.0  3.0  4.0  0.0  0.0  0.0\n",
      "2     4.0  5.0  0.0  2.0  0.0  0.0\n",
      "3     0.0  3.0  4.0  0.0  5.0  0.0\n",
      "4     3.0  0.0  0.0  2.0  4.0  0.0\n",
      "5     0.0  5.0  4.0  0.0  0.0  3.0\n",
      "6     4.0  0.0  0.0  0.0  5.0  3.0\n",
      "7     0.0  0.0  4.0  0.0  5.0  4.0\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 sklearn.decomposition.TruncatedSVD\n",
    "Lenskit offers only one way to perform SVD for collaborative filtering, namely via the BiasedSVD class. This class builds upon the TruncatedSVD class in sklearn.decomposition module. So before we use BiasedSVD, we first have to understand TruncatedSVD.\n",
    "\n",
    "The idea behind TruncatedSVD is fairly simple. To start, the CSR-matrix is directly decomposed into a $U, \\Sigma$ and $V^T$ matrix. This is contrary to usual SVD, where the mean value is subtracted from the values in te CSR-matrix before the SVD is performed. So if the original fictional ratings csr matrix is denoted with A, TruncatedSVD first performs the following step\n",
    "\n",
    "$A = U \\Sigma V^T$\n",
    "\n",
    "After the SVD, only the k most relevant latent features (or singular values) are kept. How many relevant features the model will used, must be given by the user in the construction of the svd model via the n_components parameter. This approximation boils down to the the following:\n",
    "\n",
    "$A \\approx A_k = U_k \\Sigma_k V_{k}^{T}$\n",
    "\n",
    "The function svd.fit_transform returns the matrix $U_k \\Sigma_k$  "
   ],
   "id": "3bded6245f83c229"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.842945Z",
     "start_time": "2024-09-24T18:16:17.826772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "fic_rat_mat_reduced = svd.fit_transform(fictional_ratings_matrix)\n",
    "\n",
    "print(\"\\nReduced User-Item Matrix:\")\n",
    "print(fic_rat_mat_reduced)"
   ],
   "id": "defe526393fe500d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduced User-Item Matrix:\n",
      "[[ 5.30915074 -3.65414172]\n",
      " [ 3.97486418 -4.47356679]\n",
      " [ 6.03087294  1.09853806]\n",
      " [ 3.60842275  1.67193835]\n",
      " [ 5.03382385 -2.8317348 ]\n",
      " [ 5.30668007  2.91275633]\n",
      " [ 5.93084204  3.93222308]]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To get the predicted values for the rating, we have to multiply the matrix $U_k \\Sigma_k$ with the matrix $V_{k}^{T}$. This multiplication is performed by calling the inverse_transform method of the TruncatedSVD object",
   "id": "1168de575e4590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.956883Z",
     "start_time": "2024-09-24T18:16:17.927792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "fic_rat_mat_approx = svd.inverse_transform(fic_rat_mat_reduced)\n",
    "\n",
    "print(\"\\nReconstructed User-Item Matrix (approximation):\")\n",
    "print(np.round(fic_rat_mat_approx, 2)) # Rounded for readability"
   ],
   "id": "80f767af347093cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructed User-Item Matrix (approximation):\n",
      "[[ 3.2   4.63  2.91  0.74  0.49  0.75]\n",
      " [ 2.88  4.58  2.32  0.69 -0.79  0.16]\n",
      " [ 2.16  1.92  2.86  0.41  4.07  2.07]\n",
      " [ 1.01  0.5   1.63  0.17  3.12  1.47]\n",
      " [ 2.86  3.99  2.7   0.65  0.89  0.86]\n",
      " [ 1.35  0.45  2.36  0.21  4.89  2.27]\n",
      " [ 1.32  0.07  2.58  0.18  5.91  2.69]]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.3 BiasedSVD\n",
    "In BiasedSVD, three biases are used\n",
    "* $\\mu$:   General mean\n",
    "* $b_u$:   Mean of all items per user (some users give structural higher/ lower ratings than others)\n",
    "* $b_i$:   Mean of all users per item (some items are structurally higher/ lower rated than others)\n",
    "\n",
    "BiasedSVD assumes the following model\n",
    "$A_{ui,real} = \\mu + b_u + b_i + A_{ui,pure}$\n",
    "\n",
    "BiasedSVD works according to the steps below:\n",
    "1. First a csr matrix is formed from the dataframe. \n",
    "2. Secondly, all the means are subtracted from the csr matrix. \n",
    "3. Then, it decomposes the new csr matrix. The results of this decomposition are saved in the attributes of the BiasedSVD object\n",
    "4. After this, the relevant rows and vectors are multiplied to get the relevant $A_{ui,pure}$. Thereafter, the biases are added to this value.\n",
    "\n",
    "Steps 1 until 3 are performed in the BiasedSVD.fit method. Step 4 is executed in the BiasedSVD.predict_for_user method. \n",
    "\n",
    "It is important to note that, contrary to TruncatedSVD, there is no way to compute the whole prediction matrix at once using the BiasedSVD class"
   ],
   "id": "281789870e13c5a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:37:35.175664Z",
     "start_time": "2024-09-24T18:37:35.138212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lenskit.algorithms.svd import BiasedSVD\n",
    "\n",
    "biased_svd = BiasedSVD(features=2)  # 2 latent features\n",
    "\n",
    "biased_svd.fit(fictional_ratings_df)\n",
    "\n",
    "user_id = 2\n",
    "all_items = fictional_ratings_df['item'].unique()\n",
    "b_svd_recommendations = biased_svd.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', b_svd_recommendations)"
   ],
   "id": "b4840c675f953f95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.496016\n",
      "2    4.902816\n",
      "3    3.884709\n",
      "4    2.106290\n",
      "5    4.310345\n",
      "6    3.515951\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.4 FunkSVD\n",
    "Asides from the BiasedSVD class does the lenskit module contain another class that contains the acronym SVD in its name: FunkSVD. FunkSVD is named after Simon Funk who popularized it during the Netflix Prize competition. \n",
    "\n",
    "The FunkSVD algorithm wants to decompose the ratingsmatrix A in two matrices, a U matrix representing the users and a V matrix representing the items, similar to a regular singular value decomposition. In math:\n",
    "\n",
    "$A = UV^T$\n",
    "\n",
    "However, the FunkSVD algorithm does not generate directly the U and V matrices. Instead, it calculates them row and column-wise using stochastic gradient descent (SGD). The here implemented SGD makes use of a regularization factor to prevent the entries in the U and V matrices from getting too large values. For that reason, the optimization problem looks like this:\n",
    "\n",
    "$\\min \\sum_{(u,i) \\in \\text{ratings}} (A_{ui} - \\hat{A}_{ui})^2 + \\lambda (\\|U_u\\|^2 + \\|V_i\\|^2)$\n",
    "\n",
    "In this equation\n",
    "* $A_{ui}$ stands for the real rating\n",
    "* $\\hat{A}_{ui}$ stands for the calculated rating\n",
    "* $U_u$ stands for the row representing user u in the U matrix\n",
    "* $V_i$ stands for the row representing user i in the V matrix\n",
    "* $\\lambda$ stands for the regularization penalty\n",
    "\n",
    "The number of iterations, the learning rate and regularization penalty can be specified when constructing the FunkSVD object. Furthermore, the \"number of features\" of the decomposition can also be passed in this constructor, just as was the case in the previous two SVDs.\n",
    "\n",
    "All of the above is performed by the FunkSVD.fit method. The FunkSVD.predict_for_user adds bias to the results for the model obtained by the fit method. Just like with BiasedSVD, FunkSVD can only make predictions for one user at a time.\n",
    "\n",
    "As a side note, this implementation of FunkSVD uses only one rating per iteration, making it a \"real\" SGD and not a batch process.  "
   ],
   "id": "2f8bd1514a55dd13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:03:14.004812Z",
     "start_time": "2024-09-24T20:03:13.982181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lenskit.algorithms.funksvd import FunkSVD\n",
    "\n",
    "funk_svd = FunkSVD(features=2, iterations=100, lrate=0.01, reg=0.1)\n",
    "funk_svd.fit(fictional_ratings_df)\n",
    "\n",
    "user_id = 2\n",
    "all_items = fictional_ratings_df['item'].unique()\n",
    "f_svd_recommendations = funk_svd.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', f_svd_recommendations)"
   ],
   "id": "462a17d373d5773a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.947330\n",
      "2    3.939892\n",
      "3    3.923106\n",
      "4    3.270567\n",
      "5    4.321505\n",
      "6    3.623049\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.5 BiasedMF\n",
    "One last decomposition algorithm from the lenskit module to consider is called BiasedMF (biased matrix factorization). BiasedMF wants to split the ratings matrix A in a U and V matrix, comparable to the FunkSVD. Also similar to FunkSVD, it does this using an optimization problem. However, where FunkSVD optimizes for one rating at the time, BiasedMF optimizes the whole U and V matrix at once. It does this using a technique called alternating least squares (ALS). In this technique, in one iteration, the problem is optimized for U, in the next iteration, the problem is optimized for V. \n",
    "\n",
    "The corresponding optimization problem can be stated as follows:\n",
    "\n",
    "$\\min \\sum_{(u,i) \\in A} (A_{ui} - \\hat{A}_{ui})^2 + \\lambda \\left( \\|U\\|^2 + \\|V\\|^2 + b_u^2 + b_i^2 \\right)$ "
   ],
   "id": "6f4c2cd1e5fa886e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T21:15:05.304868Z",
     "start_time": "2024-09-24T21:15:01.994327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lenskit.algorithms.als import BiasedMF\n",
    "\n",
    "biased_mf = BiasedMF(features=2, iterations=20, reg=0.1)\n",
    "\n",
    "biased_mf.fit(fictional_ratings_df)\n",
    "\n",
    "b_mf_recommendations = biased_mf.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', b_mf_recommendations)\n"
   ],
   "id": "691ea1c9de9519c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.739562\n",
      "2    4.839057\n",
      "3    3.872617\n",
      "4    2.164538\n",
      "5    3.486846\n",
      "6    3.727821\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
