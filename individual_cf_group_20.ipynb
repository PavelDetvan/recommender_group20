{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b2a1b2adc2b4d3",
   "metadata": {},
   "source": [
    "# 1 Collaborative filtering\n",
    "## 1.1 Introduction with small fictional database\n",
    "\n",
    "The first thing we want to explore are the possibilities to perform collaborative filtering using singular value decomposition (SVD). We want to do this using the lenskit python-module. Before we apply this module to the wine dataset, we first want to get a better feeling on how this module works. To do so, we first use a small fictional database. The small database is loaded into memory as a pandas dataframe in the cell below.\n",
    "\n",
    "**Important**: Lenskit works only if the version of the python interpreter is >= 3.8 and < 3.12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.756905Z",
     "start_time": "2024-09-24T18:16:17.737326Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fictional_ratings_df = pd.DataFrame({\n",
    "    'user': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7],\n",
    "    'item': [1, 2, 3, 1, 2, 4, 2, 3, 5, 1, 4, 5, 2, 3, 6, 1, 5, 6, 3, 5, 6],\n",
    "    'rating': [5, 3, 4, 4, 5, 2, 3, 4, 5, 3, 2, 4, 5, 4, 3, 4, 5, 3, 4, 5, 4]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676130af61442cb",
   "metadata": {},
   "source": [
    "If we want to apply SVD to this database, this dataframa has to be compressed to a sparse row matrix, or CSR-matrix for short. The SVD-models do this automatically, but for the sake of completeness, the CSR-matrix is shown below. Missing values are filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d8e5d1def4fa7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.800442Z",
     "start_time": "2024-09-24T18:16:17.781419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item    1    2    3    4    5    6\n",
      "user                              \n",
      "1     5.0  3.0  4.0  0.0  0.0  0.0\n",
      "2     4.0  5.0  0.0  2.0  0.0  0.0\n",
      "3     0.0  3.0  4.0  0.0  5.0  0.0\n",
      "4     3.0  0.0  0.0  2.0  4.0  0.0\n",
      "5     0.0  5.0  4.0  0.0  0.0  3.0\n",
      "6     4.0  0.0  0.0  0.0  5.0  3.0\n",
      "7     0.0  0.0  4.0  0.0  5.0  4.0\n"
     ]
    }
   ],
   "source": [
    "fictional_ratings_matrix = fictional_ratings_df.pivot(index='user', columns='item', values='rating').fillna(0)\n",
    "\n",
    "print(fictional_ratings_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bded6245f83c229",
   "metadata": {},
   "source": [
    "## 1.2 sklearn.decomposition.TruncatedSVD\n",
    "Lenskit offers only one way to perform SVD for collaborative filtering, namely via the BiasedSVD class. This class builds upon the TruncatedSVD class in sklearn.decomposition module. So before we use BiasedSVD, we first have to understand TruncatedSVD.\n",
    "\n",
    "The idea behind TruncatedSVD is fairly simple. To start, the CSR-matrix is directly decomposed into a $U, \\Sigma$ and $V^T$ matrix. This is contrary to usual SVD, where the mean value is subtracted from the values in te CSR-matrix before the SVD is performed. So if the original fictional ratings csr matrix is denoted with A, TruncatedSVD first performs the following step\n",
    "\n",
    "$A = U \\Sigma V^T$\n",
    "\n",
    "After the SVD, only the k most relevant latent features (or singular values) are kept. How many relevant features the model will used, must be given by the user in the construction of the svd model via the n_components parameter. This approximation boils down to the the following:\n",
    "\n",
    "$A \\approx A_k = U_k \\Sigma_k V_{k}^{T}$\n",
    "\n",
    "The function svd.fit_transform returns the matrix $U_k \\Sigma_k$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defe526393fe500d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.842945Z",
     "start_time": "2024-09-24T18:16:17.826772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduced User-Item Matrix:\n",
      "[[ 5.30915074 -3.65414172]\n",
      " [ 3.97486418 -4.47356679]\n",
      " [ 6.03087294  1.09853806]\n",
      " [ 3.60842275  1.67193835]\n",
      " [ 5.03382385 -2.8317348 ]\n",
      " [ 5.30668007  2.91275633]\n",
      " [ 5.93084204  3.93222308]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "fic_rat_mat_reduced = svd.fit_transform(fictional_ratings_matrix)\n",
    "\n",
    "print(\"\\nReduced User-Item Matrix:\")\n",
    "print(fic_rat_mat_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168de575e4590",
   "metadata": {},
   "source": [
    "To get the predicted values for the rating, we have to multiply the matrix $U_k \\Sigma_k$ with the matrix $V_{k}^{T}$. This multiplication is performed by calling the inverse_transform method of the TruncatedSVD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f767af347093cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:16:17.956883Z",
     "start_time": "2024-09-24T18:16:17.927792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructed User-Item Matrix (approximation):\n",
      "[[ 3.2   4.63  2.91  0.74  0.49  0.75]\n",
      " [ 2.88  4.58  2.32  0.69 -0.79  0.16]\n",
      " [ 2.16  1.92  2.86  0.41  4.07  2.07]\n",
      " [ 1.01  0.5   1.63  0.17  3.12  1.47]\n",
      " [ 2.86  3.99  2.7   0.65  0.89  0.86]\n",
      " [ 1.35  0.45  2.36  0.21  4.89  2.27]\n",
      " [ 1.32  0.07  2.58  0.18  5.91  2.69]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fic_rat_mat_approx = svd.inverse_transform(fic_rat_mat_reduced)\n",
    "\n",
    "print(\"\\nReconstructed User-Item Matrix (approximation):\")\n",
    "print(np.round(fic_rat_mat_approx, 2)) # Rounded for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281789870e13c5a5",
   "metadata": {},
   "source": [
    "## 1.3 BiasedSVD\n",
    "In BiasedSVD, three biases are used\n",
    "* $\\mu$:   General mean\n",
    "* $b_u$:   Mean of all items per user (some users give structural higher/ lower ratings than others)\n",
    "* $b_i$:   Mean of all users per item (some items are structurally higher/ lower rated than others)\n",
    "\n",
    "BiasedSVD assumes the following model\n",
    "$A_{ui,real} = \\mu + b_u + b_i + A_{ui,pure}$\n",
    "\n",
    "BiasedSVD works according to the steps below:\n",
    "1. First a csr matrix is formed from the dataframe. \n",
    "2. Secondly, all the means are subtracted from the csr matrix. \n",
    "3. Then, it decomposes the new csr matrix. The results of this decomposition are saved in the attributes of the BiasedSVD object\n",
    "4. After this, the relevant rows and vectors are multiplied to get the relevant $A_{ui,pure}$. Thereafter, the biases are added to this value.\n",
    "\n",
    "Steps 1 until 3 are performed in the BiasedSVD.fit method. Step 4 is executed in the BiasedSVD.predict_for_user method. \n",
    "\n",
    "It is important to note that, contrary to TruncatedSVD, there is no way to compute the whole prediction matrix at once using the BiasedSVD class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4840c675f953f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T18:37:35.175664Z",
     "start_time": "2024-09-24T18:37:35.138212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.496016\n",
      "2    4.902816\n",
      "3    3.884709\n",
      "4    2.106290\n",
      "5    4.310345\n",
      "6    3.515951\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from lenskit.algorithms.svd import BiasedSVD\n",
    "\n",
    "biased_svd = BiasedSVD(features=2)  # 2 latent features\n",
    "\n",
    "biased_svd.fit(fictional_ratings_df)\n",
    "\n",
    "user_id = 2\n",
    "all_items = fictional_ratings_df['item'].unique()\n",
    "b_svd_recommendations = biased_svd.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', b_svd_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8bd1514a55dd13",
   "metadata": {},
   "source": [
    "## 1.4 FunkSVD\n",
    "Asides from the BiasedSVD class does the lenskit module contain another class that contains the acronym SVD in its name: FunkSVD. FunkSVD is named after Simon Funk who popularized it during the Netflix Prize competition. \n",
    "\n",
    "The FunkSVD algorithm wants to decompose the ratingsmatrix A in two matrices, a U matrix representing the users and a V matrix representing the items, similar to a regular singular value decomposition. In math:\n",
    "\n",
    "$A = UV^T$\n",
    "\n",
    "However, the FunkSVD algorithm does not generate directly the U and V matrices. Instead, it calculates them row and column-wise using stochastic gradient descent (SGD). The here implemented SGD makes use of a regularization factor to prevent the entries in the U and V matrices from getting too large values. For that reason, the optimization problem looks like this:\n",
    "\n",
    "$\\min \\sum_{(u,i) \\in \\text{ratings}} (A_{ui} - \\hat{A}_{ui})^2 + \\lambda (\\|U_u\\|^2 + \\|V_i\\|^2)$\n",
    "\n",
    "In this equation\n",
    "* $A_{ui}$ stands for the real rating\n",
    "* $\\hat{A}_{ui}$ stands for the calculated rating\n",
    "* $U_u$ stands for the row representing user u in the U matrix\n",
    "* $V_i$ stands for the row representing user i in the V matrix\n",
    "* $\\lambda$ stands for the regularization penalty\n",
    "\n",
    "The number of iterations, the learning rate and regularization penalty can be specified when constructing the FunkSVD object. Furthermore, the \"number of features\" of the decomposition can also be passed in this constructor, just as was the case in the previous two SVDs.\n",
    "\n",
    "All of the above is performed by the FunkSVD.fit method. The FunkSVD.predict_for_user adds bias to the results for the model obtained by the fit method. Just like with BiasedSVD, FunkSVD can only make predictions for one user at a time.\n",
    "\n",
    "As a side note, this implementation of FunkSVD uses only one rating per iteration, making it a \"real\" SGD and not a batch process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462a17d373d5773a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:03:14.004812Z",
     "start_time": "2024-09-24T20:03:13.982181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numba is using threading layer omp - consider TBB\n",
      "found 1 potential runtime problems - see https://boi.st/lkpy-perf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.948304\n",
      "2    3.941181\n",
      "3    3.923538\n",
      "4    3.268863\n",
      "5    4.323116\n",
      "6    3.622740\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from lenskit.algorithms.funksvd import FunkSVD\n",
    "\n",
    "funk_svd = FunkSVD(features=2, iterations=100, lrate=0.01, reg=0.1)\n",
    "funk_svd.fit(fictional_ratings_df)\n",
    "\n",
    "user_id = 2\n",
    "all_items = fictional_ratings_df['item'].unique()\n",
    "f_svd_recommendations = funk_svd.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', f_svd_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c2cd1e5fa886e",
   "metadata": {},
   "source": [
    "## 1.5 BiasedMF\n",
    "One last decomposition algorithm from the lenskit module to consider is called BiasedMF (biased matrix factorization). BiasedMF wants to split the ratings matrix A in a U and V matrix, comparable to the FunkSVD. Also similar to FunkSVD, it does this using an optimization problem. However, where FunkSVD optimizes for one rating at the time, BiasedMF optimizes the whole U and V matrix at once. It does this using a technique called alternating least squares (ALS). In this technique, in one iteration, the problem is optimized for U, in the next iteration, the problem is optimized for V. \n",
    "\n",
    "The corresponding optimization problem can be stated as follows:\n",
    "\n",
    "$\\min \\sum_{(u,i) \\in A} (A_{ui} - \\hat{A}_{ui})^2 + \\lambda \\left( \\|U\\|^2 + \\|V\\|^2 + b_u^2 + b_i^2 \\right)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "691ea1c9de9519c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T21:15:05.304868Z",
     "start_time": "2024-09-24T21:15:01.994327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 2: 1    3.739562\n",
      "2    4.839057\n",
      "3    3.872617\n",
      "4    2.164538\n",
      "5    3.486846\n",
      "6    3.727821\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from lenskit.algorithms.als import BiasedMF\n",
    "\n",
    "biased_mf = BiasedMF(features=2, iterations=20, reg=0.1)\n",
    "\n",
    "biased_mf.fit(fictional_ratings_df)\n",
    "\n",
    "b_mf_recommendations = biased_mf.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', b_mf_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6046066",
   "metadata": {},
   "source": [
    "\n",
    "## 1.6 Applying SVD Models to Our Dataset\n",
    "\n",
    "In the previous sections, we explored various SVD-based collaborative filtering techniques using a small fictional dataset. Now, we will apply these models to our actual dataset to generate recommendations. The models we will use include:\n",
    "\n",
    "1. **BiasedSVD**: This model incorporates biases for users and items, along with the general mean, to provide more accurate predictions.\n",
    "2. **FunkSVD**: Named after Simon Funk, this model uses stochastic gradient descent to decompose the ratings matrix into user and item matrices.\n",
    "3. **BiasedMF**: This model uses alternating least squares (ALS) to optimize the user and item matrices, incorporating biases similar to BiasedSVD.\n",
    "\n",
    "### Steps to Apply the Models\n",
    "\n",
    "1. **Fit the Models**: We will fit each model to our dataset.\n",
    "2. **Generate Recommendations**: For a given user, we will generate recommendations using each model.\n",
    "3. **Compare Results**: We will compare the recommendations from different models to understand their performance.\n",
    "\n",
    "Let's proceed with applying these models to our dataset and generating recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adaffb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurim\\AppData\\Local\\Temp\\ipykernel_4400\\3693029570.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df_slim = pd.read_csv(\"XWines_Slim_1K_wines_150K_ratings\\XWines_Slim_150K_ratings.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   WineID      150000 non-null  int64         \n",
      " 1   WineName    150000 non-null  object        \n",
      " 2   Type        150000 non-null  object        \n",
      " 3   Elaborate   150000 non-null  object        \n",
      " 4   Grapes      150000 non-null  object        \n",
      " 5   Harmonize   150000 non-null  object        \n",
      " 6   ABV         150000 non-null  float64       \n",
      " 7   Body        150000 non-null  object        \n",
      " 8   Acidity     150000 non-null  object        \n",
      " 9   Code        150000 non-null  object        \n",
      " 10  Country     150000 non-null  object        \n",
      " 11  RegionID    150000 non-null  int64         \n",
      " 12  RegionName  150000 non-null  object        \n",
      " 13  WineryID    150000 non-null  int64         \n",
      " 14  WineryName  150000 non-null  object        \n",
      " 15  Vintages    150000 non-null  object        \n",
      " 16  RatingID    150000 non-null  int64         \n",
      " 17  UserID      150000 non-null  int64         \n",
      " 18  Vintage     150000 non-null  object        \n",
      " 19  Rating      150000 non-null  float64       \n",
      " 20  Date        150000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(5), object(13)\n",
      "memory usage: 24.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# first we load and preprocess the wines dataset \n",
    "\n",
    "# TODO use the whole dataset\n",
    "\n",
    "wines_df_slim = pd.read_csv(\"XWines_Slim_1K_wines_150K_ratings\\XWines_Slim_1K_wines.csv\")\n",
    "ratings_df_slim = pd.read_csv(\"XWines_Slim_1K_wines_150K_ratings\\XWines_Slim_150K_ratings.csv\")\n",
    "\n",
    "# Handle missing data (we'll drop 'Website' since it's not needed)\n",
    "wine_data_clean = wines_df_slim.drop(columns=['Website'])\n",
    "\n",
    "# Merge wines and ratings on WineID\n",
    "merged_data = pd.merge(wine_data_clean, ratings_df_slim, on='WineID')\n",
    "\n",
    "# Convert 'Date' and 'Vintage' to appropriate types\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], errors='coerce')\n",
    "merged_data['Vintage'] = merged_data['Vintage'].astype(str)\n",
    "\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00809656",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4400\\2963210123.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlenskit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBiasedSVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbiased_svd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBiasedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 2 latent features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbiased_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UserID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'WineID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Define the user ID for which to make recommendations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0muser_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yurim\\Documents\\University\\UM\\Year 3\\Period 1\\Recommender Systems\\recommender_group20\\.venv\\Lib\\site-packages\\lenskit\\algorithms\\svd.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, ratings, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[%s] computing bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mg_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mu_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_offsets_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yurim\\Documents\\University\\UM\\Year 3\\Period 1\\Recommender Systems\\recommender_group20\\.venv\\Lib\\site-packages\\lenskit\\algorithms\\bias.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, ratings, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mBias\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mbias\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m     75\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'building bias model for %d ratings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'global mean: %.3f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mnrates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrating\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yurim\\Documents\\University\\UM\\Year 3\\Period 1\\Recommender Systems\\recommender_group20\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'rating'"
     ]
    }
   ],
   "source": [
    "# Now we can fit the models to the data\n",
    "\n",
    "from lenskit.algorithms.svd import BiasedSVD\n",
    "\n",
    "biased_svd = BiasedSVD(features=2)  # 2 latent features\n",
    "\n",
    "biased_svd.fit(merged_data[['UserID', 'WineID', 'Rating']])\n",
    "\n",
    "# Define the user ID for which to make recommendations\n",
    "user_id = 18\n",
    "all_items = merged_data['WineID'].unique()\n",
    "b_svd_recommendations = biased_svd.predict_for_user(user_id, all_items)\n",
    "print(f'Recommendations for user {user_id}:', b_svd_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
