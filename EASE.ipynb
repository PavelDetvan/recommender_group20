{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RatingID   UserID  WineID Vintage  Rating                 Date\n",
      "0       143  1356810  103471    1950     4.5  2021-11-02 20:52:59\n",
      "1       199  1173759  111415    1951     5.0  2015-08-20 17:46:26\n",
      "2       348  1164877  111395    1952     5.0  2020-11-13 05:40:26\n",
      "3       374  1207665  111433    1953     5.0  2017-05-05 06:44:13\n",
      "4       834  1075841  111431    1955     5.0  2016-09-14 20:18:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurim\\AppData\\Local\\Temp\\ipykernel_2816\\983214733.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df_slim = pd.read_csv(\"XWines_Slim_1K_wines_150K_ratings\\XWines_Slim_150K_ratings.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# first we load and preprocess the wines dataset \n",
    "ratings_df_slim = pd.read_csv(\"XWines_Slim_1K_wines_150K_ratings\\XWines_Slim_150K_ratings.csv\")\n",
    "\n",
    "print(ratings_df_slim.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class EASE:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder() # encode user\n",
    "        self.item_enc = LabelEncoder() # encode item\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        \"\"\"\n",
    "        Encodes user and item IDs into numerical indices.\n",
    "\n",
    "        - Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing user and item IDs.\n",
    "\n",
    "        - Returns:\n",
    "        tuple: Encoded user and item indices.\n",
    "        \"\"\"\n",
    "        users = self.user_enc.fit_transform(df.loc[:, 'UserID'])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, 'WineID'])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "        \"\"\"\n",
    "        Fits the EASE model to the provided data.\n",
    "\n",
    "        - Parameters:\n",
    "        df (pandas.DataFrame): DataFrame with columns user_id, item_id, and (optionally) rating.\n",
    "        lambda_ (float): L2-regularization term.\n",
    "        implicit (bool): If True, ratings are ignored and taken as 1; else normalized ratings are used.\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = (\n",
    "            np.ones(df.shape[0])\n",
    "            if implicit\n",
    "            else df['Rating'].to_numpy() / df['Rating'].max()\n",
    "        )\n",
    "\n",
    "        X = csr_matrix((values, (users, items)))\n",
    "        self.X = X\n",
    "\n",
    "        G = X.T.dot(X).toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "    \n",
    "    def predict(self, train, users, items, k):\n",
    "        \"\"\"\n",
    "        Generates top-k item recommendations for the specified users.\n",
    "\n",
    "        - Parameters:\n",
    "        train (pandas.DataFrame): Training data DataFrame with columns user_id and item_id.\n",
    "        users (list): List of user IDs for whom to generate recommendations.\n",
    "        items (list): List of item IDs to consider for recommendations.\n",
    "        k (int): Number of top recommendations to return for each user.\n",
    "\n",
    "        - Returns:\n",
    "        pandas.DataFrame: DataFrame containing user_id, item_id, and predicted scores.\n",
    "        \"\"\"\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.UserID.isin(users)]\n",
    "        dd['ci'] = self.item_enc.transform(dd.WineID)\n",
    "        dd['cu'] = self.user_enc.transform(dd.UserID)\n",
    "        g = dd.groupby('cu')\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for user, group in g:\n",
    "            user_pred = self.predict_for_user(user, group, self.pred[user, :], items, k)\n",
    "            results.append(user_pred)\n",
    "\n",
    "        df = pd.concat(results)\n",
    "        df['WineID'] = self.item_enc.inverse_transform(df['WineID'])\n",
    "        df['UserID'] = self.user_enc.inverse_transform(df['UserID'])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_for_user(user, group, pred, items, k):\n",
    "        \"\"\"\n",
    "        Generates top-k item recommendations for a single user.\n",
    "\n",
    "        - Parameters:\n",
    "        user (int): Encoded user ID.\n",
    "        group (pandas.DataFrame): Grouped DataFrame for the user.\n",
    "        pred (numpy.ndarray): Predicted scores for all items for the user.\n",
    "        items (numpy.ndarray): Encoded item IDs to consider for recommendations.\n",
    "        k (int): Number of top recommendations to return.\n",
    "\n",
    "        - Returns:\n",
    "        pandas.DataFrame: DataFrame containing user_id, item_id, and predicted scores.\n",
    "        \"\"\"\n",
    "        watched = set(group['ci'])\n",
    "        candidates = [item for item in items if item not in watched]\n",
    "        pred = np.take(pred, candidates)\n",
    "\n",
    "        # Scale the predictions to the original rating range (0 to 5)\n",
    "        min_pred, max_pred = np.min(pred), np.max(pred)\n",
    "        if max_pred != min_pred:\n",
    "            pred = 5 * (pred - min_pred) / (max_pred - min_pred)\n",
    "        else:\n",
    "            pred = np.full_like(pred, 2.5)  # Set to midpoint of the range if all values are the same\n",
    "        \n",
    "\n",
    "        res = np.argpartition(pred, -k)[-k:]\n",
    "        r = pd.DataFrame(\n",
    "            {\n",
    "                \"UserID\": [user] * len(res),\n",
    "                \"WineID\": np.take(candidates, res),\n",
    "                \"Rating\": np.take(pred, res),\n",
    "            }\n",
    "        ).sort_values('Rating', ascending=False)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class EASE_sim:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder() # encode user\n",
    "        self.item_enc = LabelEncoder() # encode item\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        \"\"\"\n",
    "        Encodes user and item IDs into numerical indices.\n",
    "\n",
    "        - Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing user and item IDs.\n",
    "\n",
    "        - Returns:\n",
    "        tuple: Encoded user and item indices.\n",
    "        \"\"\"\n",
    "        users = self.user_enc.fit_transform(df.loc[:, 'UserID'])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, 'WineID'])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, similarity_matrix_path, implicit=True):\n",
    "        \"\"\"\n",
    "        Fits the EASE model to the provided data using a precomputed similarity matrix.\n",
    "\n",
    "        - Parameters:\n",
    "        df (pandas.DataFrame): DataFrame with columns user_id, item_id, and (optionally) rating.\n",
    "        similarity_matrix_path (str): Path to the precomputed item-item similarity matrix (numpy .npy file).\n",
    "        implicit (bool): If True, ratings are ignored and taken as 1; else normalized ratings are used.\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = (\n",
    "            np.ones(df.shape[0])\n",
    "            if implicit\n",
    "            else df['Rating'].to_numpy() / df['Rating'].max()\n",
    "        )\n",
    "\n",
    "        # Load the precomputed item-item similarity matrix\n",
    "        B = np.load(similarity_matrix_path)\n",
    "\n",
    "        X = coo_matrix((values, (users, items)), shape=(len(users), B.shape[1]))\n",
    "        X = X.tocsr()\n",
    "        self.X = X\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "    \n",
    "    def predict(self, train, users, items, k):\n",
    "        \"\"\"\n",
    "        Generates top-k item recommendations for the specified users.\n",
    "\n",
    "        - Parameters:\n",
    "        train (pandas.DataFrame): Training data DataFrame with columns user_id and item_id.\n",
    "        users (list): List of user IDs for whom to generate recommendations.\n",
    "        items (list): List of item IDs to consider for recommendations.\n",
    "        k (int): Number of top recommendations to return for each user.\n",
    "\n",
    "        - Returns:\n",
    "        pandas.DataFrame: DataFrame containing user_id, item_id, and predicted scores.\n",
    "        \"\"\"\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.UserID.isin(users)]\n",
    "        dd['ci'] = self.item_enc.transform(dd.WineID)\n",
    "        dd['cu'] = self.user_enc.transform(dd.UserID)\n",
    "        g = dd.groupby('cu')\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for user, group in g:\n",
    "            user_pred = self.predict_for_user(user, group, self.pred[user, :], items, k)\n",
    "            results.append(user_pred)\n",
    "\n",
    "        df = pd.concat(results)\n",
    "        df['WineID'] = self.item_enc.inverse_transform(df['WineID'])\n",
    "        df['UserID'] = self.user_enc.inverse_transform(df['UserID'])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_for_user(user, group, pred, items, k):\n",
    "        \"\"\"\n",
    "        Generates top-k item recommendations for a single user.\n",
    "\n",
    "        - Parameters:\n",
    "        user (int): Encoded user ID.\n",
    "        group (pandas.DataFrame): Grouped DataFrame for the user.\n",
    "        pred (numpy.ndarray): Predicted scores for all items for the user.\n",
    "        items (numpy.ndarray): Encoded item IDs to consider for recommendations.\n",
    "        k (int): Number of top recommendations to return.\n",
    "\n",
    "        - Returns:\n",
    "        pandas.DataFrame: DataFrame containing user_id, item_id, and predicted scores.\n",
    "        \"\"\"\n",
    "        watched = set(group['ci'])\n",
    "        candidates = [item for item in items if item not in watched]\n",
    "        pred = np.take(pred, candidates)\n",
    "\n",
    "        # Scale the predictions to the original rating range (0 to 5)\n",
    "        min_pred, max_pred = np.min(pred), np.max(pred)\n",
    "        if max_pred != min_pred:\n",
    "            pred = 5 * (pred - min_pred) / (max_pred - min_pred)\n",
    "        else:\n",
    "            pred = np.full_like(pred, 2.5)  # Set to midpoint of the range if all values are the same\n",
    "        \n",
    "\n",
    "        res = np.argpartition(pred, -k)[-k:]\n",
    "        r = pd.DataFrame(\n",
    "            {\n",
    "                \"UserID\": [user] * len(res),\n",
    "                \"WineID\": np.take(candidates, res),\n",
    "                \"Rating\": np.take(pred, res),\n",
    "            }\n",
    "        ).sort_values('Rating', ascending=False)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID  WineID  Rating\n",
      "0  1356810  103471     4.5\n",
      "1  1173759  111415     5.0\n",
      "2  1164877  111395     5.0\n",
      "3  1207665  111433     5.0\n",
      "4  1075841  111431     5.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# construct user-item mattrix with ratings as values\n",
    "user_item_matrix = ratings_df_slim.drop(columns=['RatingID','Vintage','Date'])\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train, test = train_test_split(user_item_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.34243759 0.25715279 ... 0.08090713 0.04792404 0.00931809]\n",
      " [0.34243759 1.         0.22099944 ... 0.02145987 0.02227039 0.04432614]\n",
      " [0.25715279 0.22099944 1.         ... 0.06395532 0.03669954 0.0404726 ]\n",
      " ...\n",
      " [0.08090713 0.02145987 0.06395532 ... 1.         0.13548625 0.01549924]\n",
      " [0.04792404 0.02227039 0.03669954 ... 0.13548625 1.         0.00610152]\n",
      " [0.00931809 0.04432614 0.0404726  ... 0.01549924 0.00610152 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the wine similarities array\n",
    "similarity_matrix_path = 'wine_similarities.npy'\n",
    "wine_similarities = np.load(similarity_matrix_path)\n",
    "\n",
    "# Print the array\n",
    "print(wine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preditions for EASE model:\n",
      "    UserID  WineID    Rating\n",
      "2  1000004  111479  5.000000\n",
      "4  1000004  162497  4.634106\n",
      "3  1000004  135871  4.246498\n",
      "1  1000004  167443  4.118155\n",
      "0  1000004  179044  4.092122\n",
      "\n",
      "Preditions for EASE model with precomputed similarities:\n",
      "    UserID  WineID    Rating\n",
      "3  1000004  111544  5.000000\n",
      "4  1000004  112834  4.995180\n",
      "2  1000004  113600  4.795602\n",
      "1  1000004  113288  4.742439\n",
      "0  1000004  111479  4.670854\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the models\n",
    "ease = EASE() # normal EASE model\n",
    "ease.fit(train, lambda_=0.5, implicit=False)\n",
    "\n",
    "ease_sim = EASE_sim() # EASE model with precomputed similarities\n",
    "similarity_matrix_path = 'wine_similarities.npy'\n",
    "ease_sim.fit(train, similarity_matrix_path, implicit=False)\n",
    "\n",
    "users = train['UserID'].unique()\n",
    "items = train['WineID'].unique()\n",
    "\n",
    "predictions = ease.predict(train, users, items, 5)\n",
    "print('Preditions for EASE model:')\n",
    "print(predictions.head())\n",
    "\n",
    "print()\n",
    "print('Preditions for EASE model with precomputed similarities:')\n",
    "predictions_sim = ease_sim.predict(train, users, items, 5)\n",
    "print(predictions_sim.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7658744467276951\n",
      "RMSE: 0.8751425293788979\n",
      "\n",
      "MSE with precomputed similarities: 0.9666028493119528\n",
      "RMSE with precomputed similarities: 0.9831596255501712\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the recommendations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Merge predictions with actual ratings on 'user_id' and 'item_id'\n",
    "merged = pd.merge(predictions, test, on=['UserID', 'WineID'], suffixes=('_pred', '_actual'))\n",
    "merged_sim = pd.merge(predictions_sim, test, on=['UserID', 'WineID'], suffixes=('_pred', '_actual'))\n",
    "\n",
    "# Drop rows with NaN values in the 'Rating_actual' column\n",
    "merged = merged.dropna(subset=['Rating_actual'])\n",
    "merged_sim = merged_sim.dropna(subset=['Rating_actual'])\n",
    "\n",
    "# Extract the predicted and actual scores\n",
    "predicted_scores = merged['Rating_pred']\n",
    "actual_scores = merged['Rating_actual']\n",
    "\n",
    "predicted_scores_sim = merged_sim['Rating_pred']\n",
    "actual_scores_sim = merged_sim['Rating_actual']\n",
    "\n",
    "# Calculate MSE and RMSE\n",
    "mse = mean_squared_error(actual_scores, predicted_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mse_sim = mean_squared_error(actual_scores_sim, predicted_scores_sim)\n",
    "rmse_sim = np.sqrt(mse_sim)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'MSE with precomputed similarities: {mse_sim}')\n",
    "print(f'RMSE with precomputed similarities: {rmse_sim}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
